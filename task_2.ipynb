{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739aea99",
   "metadata": {},
   "source": [
    "### Задача 2  \n",
    "\n",
    "Вам доступны следующие фреймы данных: \n",
    "\n",
    "- Таблица с информацией о среднедневном спросе на каждый товар для каждой локации:  \n",
    "\n",
    "| product | location | demand |\n",
    "|---|---|---|\n",
    "| 1 | 01 | 100 |\n",
    "| 1 | 02 | 110 |\n",
    "| 2 | 01 | 120 |\n",
    "| 2 | 02 | 90 |\n",
    "| 3 | 01 | 70 |\n",
    "| 3 | 02 | 80 |\n",
    "\n",
    "`product` — уникальный идентификатор продукта  \n",
    "`location` — уникальный идентификатор локации  \n",
    "`demand` — значение среднедневного спроса на конкретный товар в конкретной локации в единицах товара  \n",
    "\n",
    "- Таблица с информацией о складских запасах на уровне месяца:  \n",
    "\n",
    "| product | location | stock |\n",
    "|---|---|---|\n",
    "| 1 | 01 | 1000 |\n",
    "| 1 | 02 | 400 |\n",
    "| 2 | 01 | 300 |\n",
    "| 2 | 02 | 250 |\n",
    "\n",
    "`product` — уникальный идентификатор продукта  \n",
    "`stock` — уровень запасов в единицах товара на уровне месяца  \n",
    "\n",
    "В качестве примера рассмотрим июнь 2023 года. Вам необходимо сформировать витрину данных, в которой для каждой пары товар-локация на уровне каждой технической недели* будет рассчитано прогнозируемое значение количества проданных товаров (с учетом среднедневного спроса) и количество остатков товара на складе. \n",
    "\n",
    "Техническая неделя — это календарная неделя или часть календарной недели, которая «укладывается» в один календарный месяц. Например, в августе 2023 года вам доступны следующие технические недели: \n",
    "\n",
    "01.08—06.08\n",
    "\n",
    "07.08—13.08\n",
    "\n",
    "14.08—20.08\n",
    "\n",
    "21.08—27.08\n",
    "\n",
    "28.08—31.08\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598cc27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861bf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[8]\")\\\n",
    "    .appName(\"SparkFirst\")\\\n",
    "    .config(\"spark.executor.memory\", \"10g\")\\\n",
    "    .config(\"spark.executor.cores\", 5)\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", 5)\\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1fa1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "avg_day_demand_schema = StructType([\n",
    "    StructField('product', IntegerType(), True),\n",
    "    StructField('location', StringType(), True),\n",
    "    StructField('demand', IntegerType(), True)\n",
    "])\n",
    "\n",
    "product_stock_schema = StructType([\n",
    "    StructField('product', IntegerType(), True),\n",
    "    StructField('location', StringType(), True),\n",
    "    StructField('stock', IntegerType(), True)\n",
    "])\n",
    "\n",
    "avg_day_demand_data = [\n",
    "    (1, \"01\", 100),\n",
    "    (1, \"02\", 110),\n",
    "    (2, \"01\", 120),\n",
    "    (2, \"02\", 90),\n",
    "    (3, \"01\", 70),\n",
    "    (3, \"02\", 80)\n",
    "]\n",
    "\n",
    "product_stock_data = [\n",
    "    (1, \"01\", 1000),\n",
    "    (1, \"02\", 400),\n",
    "    (2, \"01\", 300),\n",
    "    (2, \"02\", 250)\n",
    "]\n",
    "\n",
    "\n",
    "avg_day_demand_df = spark.createDataFrame(\n",
    "    data=avg_day_demand_data, schema=avg_day_demand_schema)\n",
    "product_stock_df = spark.createDataFrame(\n",
    "    data=product_stock_data, schema=product_stock_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dfc7c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|product|location|demand|\n",
      "+-------+--------+------+\n",
      "|      1|      01|   100|\n",
      "|      1|      02|   110|\n",
      "|      2|      01|   120|\n",
      "|      2|      02|    90|\n",
      "|      3|      01|    70|\n",
      "|      3|      02|    80|\n",
      "+-------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_day_demand_df.createOrReplaceTempView(\"avg_day_demand\")\n",
    "avg_day_demand_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3380351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|product|location|stock|\n",
      "+-------+--------+-----+\n",
      "|      1|      01| 1000|\n",
      "|      1|      02|  400|\n",
      "|      2|      01|  300|\n",
      "|      2|      02|  250|\n",
      "+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_stock_df.createOrReplaceTempView(\"product_stock\")\n",
    "product_stock_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc003c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2023-08-01|\n",
      "|2023-08-02|\n",
      "|2023-08-03|\n",
      "|2023-08-04|\n",
      "|2023-08-05|\n",
      "|2023-08-06|\n",
      "|2023-08-07|\n",
      "|2023-08-08|\n",
      "|2023-08-09|\n",
      "|2023-08-10|\n",
      "|2023-08-11|\n",
      "|2023-08-12|\n",
      "|2023-08-13|\n",
      "|2023-08-14|\n",
      "|2023-08-15|\n",
      "|2023-08-16|\n",
      "|2023-08-17|\n",
      "|2023-08-18|\n",
      "|2023-08-19|\n",
      "|2023-08-20|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "d1 = date(2023, 8, 1)  # начальная дата\n",
    "d2 = date(2023, 9, 1)  # конечная дата\n",
    "\n",
    "delta = d2 - d1        # timedelta\n",
    "\n",
    "calendar_data = pd. DataFrame([(d1 + timedelta(i)).strftime(\"%Y-%m-%d\")\n",
    "                              for i in range(delta.days)], columns=['date'])\n",
    "calendar_df = spark.createDataFrame(calendar_data)\n",
    "calendar_df.createOrReplaceTempView(\"calendar\")\n",
    "calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d69cbda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|week_number|day_in_week|\n",
      "+-----------+-----------+\n",
      "|         31|          6|\n",
      "|         32|          7|\n",
      "|         33|          7|\n",
      "|         34|          7|\n",
      "|         35|          4|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "technical_weeks_df = spark.sql(\"\"\"\n",
    "WITH calendar_weeks AS (\n",
    "    select\n",
    "        date,\n",
    "        WEEKOFYEAR(to_date(cast(date as date), \"yyyy-mm-dd\")) as week_number\n",
    "    from calendar\n",
    "),\n",
    "calendar_days_in_week AS (\n",
    "    select\n",
    "        week_number,\n",
    "        count(week_number) OVER (partition by week_number) as day_in_week\n",
    "    from calendar_weeks\n",
    ")\n",
    "select\n",
    "    week_number,\n",
    "    day_in_week\n",
    "from calendar_days_in_week\n",
    "group by week_number, day_in_week\n",
    "\"\"\")\n",
    "technical_weeks_df.createOrReplaceTempView(\"technical_weeks\")\n",
    "technical_weeks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5181a613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"W\"   - \"week\" - номер недели \n",
      "\"P\"   - \"product\" - id продукта \n",
      "\"L\"   - \"location\" - id локации \n",
      "\"WD\"  - \"weekly_demand\" - недельный спрос на товар в локации \n",
      "\"CWD\" - \"cumulative_weekly_demand\" - недельный спрос на товар в локации, нарастающим итогом \n",
      "\"SPM\" - \"stock_per_month\" - товарный запас на месяц \n",
      "\"SWB\" - \"stock_week_beginning\" - товарный запас на начало недели \n",
      "\"SWE\" - \"stock_week_end\" - товарный запас на конец недели \n",
      "\"SS\"  - \"stock_shortage\" - дефицит товара на конец недели  \n",
      "\"sales_forecast\" - прогнозируемое значение количества проданных товаров \n",
      "\n",
      "+---+---+---+---+----+----+----+---+-----+--------------+\n",
      "|  W|  P|  L| WD| CWD| SPM| SWB|SWE|   SS|sales_forecast|\n",
      "+---+---+---+---+----+----+----+---+-----+--------------+\n",
      "| 31|  1| 01|600| 600|1000|1000|400|    0|           600|\n",
      "| 32|  1| 01|700|1300|1000| 400|  0| -300|           400|\n",
      "| 33|  1| 01|700|2000|1000|   0|  0|-1000|             0|\n",
      "| 34|  1| 01|700|2700|1000|   0|  0|-1700|             0|\n",
      "| 35|  1| 01|400|3100|1000|   0|  0|-2100|             0|\n",
      "| 31|  1| 02|660| 660| 400| 400|  0| -260|           400|\n",
      "| 32|  1| 02|770|1430| 400|   0|  0|-1030|             0|\n",
      "| 33|  1| 02|770|2200| 400|   0|  0|-1800|             0|\n",
      "| 34|  1| 02|770|2970| 400|   0|  0|-2570|             0|\n",
      "| 35|  1| 02|440|3410| 400|   0|  0|-3010|             0|\n",
      "| 31|  2| 01|720| 720| 300| 300|  0| -420|           300|\n",
      "| 32|  2| 01|840|1560| 300|   0|  0|-1260|             0|\n",
      "| 33|  2| 01|840|2400| 300|   0|  0|-2100|             0|\n",
      "| 34|  2| 01|840|3240| 300|   0|  0|-2940|             0|\n",
      "| 35|  2| 01|480|3720| 300|   0|  0|-3420|             0|\n",
      "| 31|  2| 02|540| 540| 250| 250|  0| -290|           250|\n",
      "| 32|  2| 02|630|1170| 250|   0|  0| -920|             0|\n",
      "| 33|  2| 02|630|1800| 250|   0|  0|-1550|             0|\n",
      "| 34|  2| 02|630|2430| 250|   0|  0|-2180|             0|\n",
      "| 35|  2| 02|360|2790| 250|   0|  0|-2540|             0|\n",
      "+---+---+---+---+----+----+----+---+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recency = spark.sql(\"\"\"\n",
    "WITH 1temp AS (\n",
    "    SELECT\n",
    "    avg_day_demand.product as product,\n",
    "    avg_day_demand.location as location,\n",
    "    avg_day_demand.demand as demand,\n",
    "    product_stock.stock as stock\n",
    "    FROM avg_day_demand\n",
    "    JOIN product_stock ON product_stock.location = avg_day_demand.location AND product_stock.product = avg_day_demand.product\n",
    "),\n",
    "2temp AS (\n",
    "    select \n",
    "        *,\n",
    "        sum(demand * day_in_week) OVER (PARTITION BY product, location ORDER BY week_number) as demand_sum,\n",
    "        stock - sum(demand * day_in_week) OVER (PARTITION BY product, location ORDER BY week_number) as stock_balance\n",
    "    from technical_weeks\n",
    "    join 1temp\n",
    ")\n",
    "select \n",
    "    week_number as W,\n",
    "    product as P,\n",
    "    location as L,\n",
    "    demand * day_in_week as WD,\n",
    "    demand_sum as CWD,\n",
    "    stock as SPM,\n",
    "    CASE\n",
    "        WHEN stock_balance + (demand * day_in_week) > 0 THEN stock_balance + (demand * day_in_week) \n",
    "        ELSE 0\n",
    "    END as SWB,\n",
    "    CASE\n",
    "        WHEN stock_balance > 0 THEN stock_balance \n",
    "        ELSE 0\n",
    "    END as SWE,\n",
    "    CASE\n",
    "        WHEN stock_balance >= demand THEN 0\n",
    "        WHEN stock_balance <= demand THEN stock_balance + (demand * day_in_week) - demand * day_in_week\n",
    "        ELSE 0\n",
    "    END as SS,\n",
    "    CASE\n",
    "        WHEN stock_balance > 0  AND demand <= stock_balance THEN demand * day_in_week\n",
    "        WHEN stock_balance > 0  AND demand >= stock_balance THEN demand * day_in_week\n",
    "        WHEN stock_balance + demand * day_in_week > 0 THEN stock_balance + demand * day_in_week\n",
    "        ELSE 0\n",
    "    END as sales_forecast\n",
    "from 2temp\n",
    "ORDER BY product, location, week_number \n",
    "\n",
    "\"\"\")\n",
    "print('\"W\"   - \"week\" - номер недели \\n'\n",
    "     + '\"P\"   - \"product\" - id продукта \\n'\n",
    "     + '\"L\"   - \"location\" - id локации \\n'\n",
    "     + '\"WD\"  - \"weekly_demand\" - недельный спрос на товар в локации \\n'\n",
    "     + '\"CWD\" - \"cumulative_weekly_demand\" - недельный спрос на товар в локации, нарастающим итогом \\n'\n",
    "     + '\"SPM\" - \"stock_per_month\" - товарный запас на месяц \\n'\n",
    "     + '\"SWB\" - \"stock_week_beginning\" - товарный запас на начало недели \\n'\n",
    "     + '\"SWE\" - \"stock_week_end\" - товарный запас на конец недели \\n'\n",
    "     + '\"SS\"  - \"stock_shortage\" - дефицит товара на конец недели  \\n'\n",
    "     + '\"sales_forecast\" - прогнозируемое значение количества проданных товаров \\n')\n",
    "recency.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f1d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
